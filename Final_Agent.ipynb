{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jgwCz7ZUgVR"
      },
      "source": [
        "## 套件、環境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxJlXbgvUpUU",
        "outputId": "91ad015d-4503-406a-a997-c9eb2b443000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['txtdata',\n",
              " '基本學習',\n",
              " 'WebSearchSummary.ipynb',\n",
              " 'csvdata',\n",
              " 'DemoAgent0523.ipynb',\n",
              " 'WebBrowse.ipynb',\n",
              " 'DemoAgent0525',\n",
              " '0530Agent.gdoc',\n",
              " 'Agent0530.ipynb',\n",
              " '0601Agent',\n",
              " 'Final_Agent']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Colab/富邦') #切換該目錄\n",
        "os.listdir() #確認目錄內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOiltIleUJdb",
        "outputId": "41bc50b3-b11c-4904-c885-60154997d602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.218-py3-none-any.whl (1.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk>=0.0.17 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.17-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.8 langchain-0.0.218 langchainplus-sdk-0.0.17 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32002 sha256=8f6409b83af791280f8896f5940ae62db9863e00893e50bd80ca937d219dcd64\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.7.10-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argilla (from unstructured)\n",
            "  Downloading argilla-1.11.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.2)\n",
            "Collecting msg-parser (from unstructured)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Collecting pdf2image (from unstructured)\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.4.0)\n",
            "Collecting pypandoc (from unstructured)\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Collecting python-docx (from unstructured)\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured)\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.10)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Collecting httpx<0.24,>=0.15 (from argilla->unstructured)\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla->unstructured)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (23.1)\n",
            "Requirement already satisfied: pydantic>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.10.9)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (4.65.0)\n",
            "Collecting backoff (from argilla->unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting monotonic (from argilla->unstructured)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting rich<=13.0.1 (from argilla->unstructured)\n",
            "  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (2.0.12)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured)\n",
            "  Downloading cryptography-41.0.1-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting XlsxWriter>=0.5.7 (from python-pptx->unstructured)\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.7->argilla->unstructured) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<=13.0.1->argilla->unstructured)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.7.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (1.1.1)\n",
            "Building wheels for collected packages: python-docx, python-pptx, olefile\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=e06a9365b3526fa04eb33774a5dca2fbcc2eb9279a1634f6fecab3b184fd3b27\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=2f7cd5497ebe1e4ad732b015f00a44e18b9ed2de644b78605af1aae971deb20d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=3f8337d5b6baff692063e95cf580381b703ee77685974b287e48523c55f4d3b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built python-docx python-pptx olefile\n",
            "Installing collected packages: rfc3986, monotonic, filetype, commonmark, XlsxWriter, rich, python-magic, python-docx, pypandoc, pdf2image, olefile, h11, deprecated, backoff, python-pptx, msg-parser, httpcore, cryptography, pdfminer.six, httpx, argilla, unstructured\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.4.2\n",
            "    Uninstalling rich-13.4.2:\n",
            "      Successfully uninstalled rich-13.4.2\n",
            "Successfully installed XlsxWriter-3.1.2 argilla-1.11.0 backoff-2.2.1 commonmark-0.9.1 cryptography-41.0.1 deprecated-1.2.14 filetype-1.2.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 monotonic-1.6 msg-parser-1.2.0 olefile-0.46 pdf2image-1.16.3 pdfminer.six-20221105 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 rfc3986-1.5.0 rich-13.0.1 unstructured-0.7.10\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.6.3)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.16)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.3.0 loguru-0.7.0 pinecone-client-2.2.2\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20221105)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (41.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (8.4.0)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=523251fd5cab592f6ecc0d89834066a028e801bafadaded5795e9b95fbc27d1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence_transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting text2vec\n",
            "  Downloading text2vec-1.2.1.tar.gz (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from text2vec) (0.42.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from text2vec) (0.7.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from text2vec) (4.30.2)\n",
            "Collecting datasets (from text2vec)\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from text2vec) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from text2vec) (1.2.2)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from text2vec) (4.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from text2vec) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->text2vec) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->text2vec) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->text2vec) (6.3.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->text2vec) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->text2vec)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->text2vec) (2.27.1)\n",
            "Collecting xxhash (from datasets->text2vec)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->text2vec)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->text2vec) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->text2vec) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets->text2vec) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->text2vec) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->text2vec) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text2vec) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text2vec) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->text2vec) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->text2vec) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->text2vec) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->text2vec) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->text2vec) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->text2vec) (0.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->text2vec) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->text2vec) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->text2vec) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->text2vec) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->text2vec) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->text2vec) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->text2vec) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->text2vec) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->text2vec) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->text2vec) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->text2vec) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->text2vec) (3.4)\n",
            "Building wheels for collected packages: text2vec\n",
            "  Building wheel for text2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for text2vec: filename=text2vec-1.2.1-py3-none-any.whl size=57699 sha256=e951bc74db90f05c252ec004e729a9fcede6fa308b48abdfdf42dda7b58f556b\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/79/ca/1ff897a07a3a67009bf5dd67165e8f4d6cd73a5aed7c7cb8c9\n",
            "Successfully built text2vec\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets, text2vec\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 multiprocess-0.70.14 text2vec-1.2.1 xxhash-3.2.0\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.1\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.11.1-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.8/257.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.11.1\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3957 sha256=7e876c5c633dccd76c0249d70493ed43f44da68eac6035f07454da2bb5524f39\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n",
            "Collecting google-serp-api\n",
            "  Downloading google_serp_api-1.0.3-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-serp-api) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-serp-api) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-serp-api) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->google-serp-api) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-serp-api) (3.4)\n",
            "Installing collected packages: google-serp-api\n",
            "Successfully installed google-serp-api-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install google-search-results\n",
        "!pip install unstructured\n",
        "!pip install pinecone-client\n",
        "!pip install pdfminer.six\n",
        "!pip install tiktoken\n",
        "!pip install pdf2image\n",
        "!pip install pytesseract\n",
        "!pip install sentence_transformers\n",
        "!pip install text2vec\n",
        "!pip install youtube-transcript-api\n",
        "!pip install pytube\n",
        "!pip install pypdf\n",
        "!pip install docx2txt\n",
        "!pip install google-serp-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ae-idEUioQ",
        "outputId": "808974a8-b54a-44f0-82bf-de5e1cc49603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import math, os, random, csv\n",
        "#from config import OPEN_API_KEY, PINECONE_KEY, SERP_API_KEY\n",
        "from tabnanny import verbose\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# log and save\n",
        "import json, logging, pickle, sys, shutil, copy\n",
        "from argparse import ArgumentParser, Namespace\n",
        "from pathlib import Path\n",
        "from copy import copy\n",
        "# %matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "\n",
        "import torch\n",
        "from langchain.vectorstores import Pinecone\n",
        "import pinecone\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain import OpenAI\n",
        "from langchain.agents import AgentType\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.document_loaders import UnstructuredExcelLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from typing import List, Union\n",
        "import zipfile\n",
        "import re\n",
        "from langchain import SerpAPIWrapper, LLMChain, LLMMathChain\n",
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
        "from langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\n",
        "from langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\n",
        "from langchain.vectorstores import Pinecone\n",
        "import pinecone\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
        "\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from text2vec import SentenceModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "D5P28IpwVJ0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c0f840-7fea-4eb4-b876-07bb83fd8c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-06-29 03:19:02.158\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtext2vec.sentence_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m76\u001b[0m - \u001b[34m\u001b[1mUse device: cpu\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = ''\n",
        "os.environ[\"SERPAPI_API_KEY\"] = ''\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "#OpenAI类默认对应 “text-davinci-003” 版本：\n",
        "#OpenAIChat类默认是 \"gpt-3.5-turbo\"版本\n",
        "#OpenAI是即将被弃用的方法，最好是用ChatOpenAI\n",
        "model = SentenceModel('shibing624/text2vec-base-chinese')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFR8dD4cUwFn"
      },
      "source": [
        "# 正文：嘗試改用其他Agent, memory type\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name='shibing624/text2vec-base-chinese', model_kwargs={'device': EMBEDDING_DEVICE})  #768維度\n",
        "llm_chat = ChatOpenAI(temperature=0) #GPT-3.5-turbo\n",
        "llm_chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-qHHGLjelFp",
        "outputId": "2403a2b0-ac70-4cdc-f684-eab05bdacee8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_txt(file_pth: str):\n",
        "    '''\n",
        "    folder中的所有txt的文件, 邏輯為looping over all files inside using DirectoryLoader, 其中再用各種DocumentLoader\n",
        "    可以設定glob&loader_cls來指定只讀哪些類型的文件, 用指定的loader讀, silent_error代表自動略過無法被讀的檔\n",
        "    也可以用較為泛化的UnstructuredFileLoader, 自動判斷是哪種文件形式並解析\n",
        "    '''\n",
        "    loader = DirectoryLoader(f'{file_pth}', glob='**/*.txt', loader_cls=TextLoader, silent_errors=True)\n",
        "    # 將數據轉成 document形式 之後儲存到向量資料庫\n",
        "    documents = loader.load()\n",
        "    #選擇 text splitter, 目前選用較新且有效的RecursiveCTS，之後可能改用for中文的spacy\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=1000, chunk_overlap=50, separators=[\" \", \",\", \"\\n\", \"\\n\\n\", \"\\t\", \"\"]\n",
        "    )\n",
        "    split_docs = text_splitter.split_documents(documents)\n",
        "    return split_docs\n",
        "\n",
        "def init_csv(file_pth: str):\n",
        "    # my_csv_loader = CSVLoader(file_path=f'{file_pth}',encoding=\"utf-8\",\n",
        "    #                           csv_args={'delimiter': ','\n",
        "    # })\n",
        "    loader = DirectoryLoader(f'{file_pth}', glob='**/*.csv', loader_cls=CSVLoader, silent_errors=True)\n",
        "    documents = loader.load()\n",
        "    split_docs = documents #這份csv資料已經人為切割\n",
        "    return split_docs"
      ],
      "metadata": {
        "id": "Tv3gspOSxvgG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdtpDhrJUwve",
        "outputId": "23faae03-8c74-4405-9746-516c9fb5fd62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "pinecone.init(\n",
        "  api_key=\"\",\n",
        "  environment=\"us-west1-gcp-free\"\n",
        ")\n",
        "index_name=\"demo-langchain\" #這邊的embedding存成768維度 #open ai embedding為1536向量\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        name=index_name,\n",
        "        metric='cosine', #or dotproduct\n",
        "        dimensions=768\n",
        "    )\n",
        "index = pinecone.Index(index_name)\n",
        "index.describe_index_stats() #看現在向量資料庫中有多少vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 初始化：把資料放進資料庫(csv, txt data) #包含武俠&富邦+costco\n",
        "#另類的儲存資料方式如官網，可保存meta data如title：https://www.pinecone.io/learn/langchain-retrieval-augmentation\n",
        "'''儲存數據到線上(只要做一次)'''\n",
        "if not index.describe_index_stats()['total_vector_count']:\n",
        "    doc_chunks = []\n",
        "    txt_docs = init_txt('./txtdata/') #novel, credit\n",
        "    csv_docs = init_csv('./csvdata/') #富邦Costco格式化.csv\n",
        "    doc_chunks.extend(txt_docs)\n",
        "    doc_chunks.extend(csv_docs)\n",
        "    print(len(doc_chunks))\n",
        "    Pinecone.from_texts([t.page_content for t in doc_chunks], embeddings, index_name=index_name)\n",
        "\n",
        "docsearch = Pinecone.from_existing_index(index_name,embeddings) #傳入當初embedding的方法\n",
        "index.describe_index_stats() #看現在向量資料庫中有多少vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gBHT9GmxJ2U",
        "outputId": "99c8ceef-1409-4da9-aa8f-cbc60b669d8d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 768,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 442}},\n",
              " 'total_vector_count': 442}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Y033k5WrWb"
      },
      "source": [
        "## 模板 （Agent, tool, chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ScO0Z2cZhgk"
      },
      "source": [
        "## 定義Tools的集合"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_ryyjqFZkqU"
      },
      "source": [
        "#### 假資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "qFiw5tkoZf84"
      },
      "outputs": [],
      "source": [
        "CONTEXT_QA_Template = \"\"\"\n",
        "根据以下提供的信息，回答用户的问题\n",
        "信息：{context}\n",
        "\n",
        "问题：{query}\n",
        "\"\"\"\n",
        "CONTEXT_QA_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"context\", \"query\"],\n",
        "    template=CONTEXT_QA_Template,\n",
        ")\n",
        "class FugeDataSource:\n",
        "    def __init__(self, llm:ChatOpenAI(temperature=0.2)):\n",
        "        self.llm = llm\n",
        "\n",
        "    def find_product_description(self, product_name: str) -> str:\n",
        "        \"\"\"模拟公司产品的数据库\"\"\"\n",
        "        product_info = {\n",
        "            \"好快活\": \"好快活是一个营销人才平台，以社群+公众号+小程序结合的运营模式展开，帮助企业客户连接并匹配充满才华的营销人才。\",\n",
        "            \"Rimix\": \"Rimix通过采购流程数字化、完备的项目数据存储记录及标准的供应商管理体系，帮助企业实现采购流程, 透明合规可追溯，大幅节约采购成本。Rimix已为包括联合利华，滴滴出行等多家广告主提供服务，平均可为客户节约采购成本30%。\",\n",
        "            \"Bid Agent\": \"Bid Agent是一款专为中国市场设计的搜索引擎优化管理工具，支持5大搜索引擎。Bid Agent平均为广告主提升18%的投放效果，同时平均提升47%的管理效率。目前已为阳狮广告、GroupM等知名4A公司提供服务与支持。\",\n",
        "        }\n",
        "        return product_info.get(product_name, \"没有找到这个产品\")\n",
        "\n",
        "    def find_company_info(self, query: str) -> str:\n",
        "        \"\"\"模拟公司介绍文档数据库，让llm根据抓取信息回答问题\"\"\"\n",
        "        context = \"\"\"\n",
        "        关于产品：\"让广告技术美而温暖\"是复歌的产品理念。在努力为企业客户创造价值的同时，也希望让使用复歌产品的每个人都能感受到技术的温度。\n",
        "        我们关注用户的体验和建议，我们期待我们的产品能够给每个使用者的工作和生活带来正面的改变。\n",
        "        我们崇尚技术，用科技的力量使工作变得简单，使生活变得更加美好而优雅，是我们的愿景。\n",
        "        企业文化：复歌是一个非常年轻的团队，公司大部分成员是90后。\n",
        "        工作上，专业、注重细节、拥抱创新、快速试错。\n",
        "        协作中，开放、坦诚、包容、还有一点点举重若轻的幽默感。\n",
        "        以上这些都是复歌团队的重要特质。\n",
        "        在复歌，每个人可以平等地表达自己的观点和意见，每个人的想法和意愿都会被尊重。\n",
        "        如果你有理想，并拥有被理想所驱使的自我驱动力，我们期待你的加入。\n",
        "        \"\"\"\n",
        "        prompt = CONTEXT_QA_PROMPT.format( context=context, query=query )\n",
        "        return self.llm(prompt = prompt)\n",
        "fuge_data_source = FugeDataSource(llm_chat) #初始化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz8o5NUZZuEX"
      },
      "source": [
        "#### 公司內部文檔搜尋QA\n",
        "包含score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "1eA3Z0KFHKpJ"
      },
      "outputs": [],
      "source": [
        "#### 分為兩段：\n",
        "# - 第一段：得到前k筆資料是有價值的(score大於某門檻)\n",
        "# - 第二段：讓retrievalQA去搜尋前k筆資料並依據其作出回答\n",
        "\n",
        "fubon_question_prompt_template = \"\"\"Use the following portion of a long document to see if any of the text is relevant to answer the question.\n",
        "Return any relevant text.\n",
        "{context}\n",
        "Question: {question}\n",
        "Relevant text, if any:\"\"\" #context即是向量搜尋取回的文件們\n",
        "FUBON_QUESTION_PROMPT = PromptTemplate(\n",
        "    template=fubon_question_prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "fubon_combine_prompt_template = \"\"\"你是個專業文檔師，你的任務是在你的回覆中，\n",
        "，保留大部分我給定的資訊，並把段落結合在一起.\n",
        "\n",
        "QUESTION: {question}\n",
        "=========\n",
        "{summaries}\n",
        "=========\n",
        "Answer in traditional Chinese:\"\"\"\n",
        "FUBON_COMBINE_PROMPT = PromptTemplate(\n",
        "    template=fubon_combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
        ")\n",
        "class FubonDataSource:\n",
        "    def __init__(self, llm:OpenAI(temperature=0)):\n",
        "        self.llm = llm\n",
        "    def find_doc_above_score(self, query: str) -> str:\n",
        "        \"\"\"讓chain知道前幾筆資料是有用的, pass到search.kwarg 因pinecone+langchain不支援同時取score\"\"\"\n",
        "        model = SentenceModel('shibing624/text2vec-base-chinese')\n",
        "        query_embedd = model.encode(query, convert_to_numpy=True).tolist()\n",
        "        response = index.query(query_embedd, top_k=2, include_metadata=True) #top k為設定取回幾篇最多\n",
        "        threshold = 0.60\n",
        "        above_criterion_cnt = 0\n",
        "        for data in response['matches']:\n",
        "          if data['score'] < threshold:\n",
        "            break;\n",
        "          print(data)\n",
        "          above_criterion_cnt += 1\n",
        "        print(f\"\\nHow many docs match the criterion? {above_criterion_cnt} docs\\n\")\n",
        "        return above_criterion_cnt\n",
        "    def return_doc_summary(self, query: str) -> str:\n",
        "        k = self.find_doc_above_score(query)\n",
        "\n",
        "        if k == 0: return '沒有內部相符的文檔'\n",
        "        data_retriever = RetrievalQA.from_chain_type(llm=self.llm,\n",
        "                                        chain_type=\"map_reduce\",\n",
        "                                        retriever=docsearch.as_retriever(search_kwargs={\"k\": k}),\n",
        "                                        chain_type_kwargs = {\"verbose\": False,\n",
        "                                                              \"question_prompt\": FUBON_QUESTION_PROMPT, #注意是question_prompt\n",
        "                                                              \"combine_prompt\": FUBON_COMBINE_PROMPT,\n",
        "                                                            },\n",
        "                                        return_source_documents=False)\n",
        "        return data_retriever.run(query)\n",
        "\n",
        "retrieval_llm = ChatOpenAI(temperature=0)\n",
        "fubon_data_source = FubonDataSource(retrieval_llm) #初始化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0wRbz8LdvBL"
      },
      "source": [
        "#### 搜尋數篇網路文章並總結"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "aAag-SzUdzY4"
      },
      "outputs": [],
      "source": [
        "def sumWebAPI(input_query: str) :\n",
        "    '''依照關鍵字搜尋google前n個網址並總結'''\n",
        "\n",
        "    num_news = 2 # 找前2篇網站\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=400, chunk_overlap=10, separators=[\" \", \",\", \"\\n\", \"\\n\\n\", \"\\t\", \"\"]\n",
        "    )\n",
        "\n",
        "    # refine方法的template\n",
        "    prompt_template = \"\"\"Write a concise summary about 100 words of the following:\n",
        "\n",
        "    {text}\n",
        "\n",
        "    CONCISE SUMMARY IN Chinese:\"\"\"\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "    refine_template = (\n",
        "            \"\"\"Your job is to produce a final summary so that a reader will have a full understanding of what happened\n",
        "            We have provided an existing summary up to a certain point: {existing_answer}\n",
        "            We have the opportunity to refine the existing summary\n",
        "            (only if needed) with some more context below.\n",
        "            Context:\n",
        "            ------------\n",
        "            {text}\n",
        "            ------------\n",
        "            Given the new context, refine the original summary\n",
        "            If the context isn't useful, return the original summary.\n",
        "            The response should be in bullet points, traditional Chinese\"\"\"\n",
        "    )\n",
        "    refine_prompt = PromptTemplate(\n",
        "        input_variables=[\"existing_answer\", \"text\"],\n",
        "        template=refine_template,\n",
        "    )\n",
        "    # Google search Api params\n",
        "    params = {\n",
        "      \"q\": f\"{input_query}\",\n",
        "      \"location\": \"Taiwan\",\n",
        "      \"hl\": \"tw\", #國家\n",
        "      \"gl\": \"us\",\n",
        "      \"google_domain\": \"google.com\",\n",
        "      # your api key\n",
        "      \"api_key\": \"\",\n",
        "      \"num\": f\"{num_news}\"\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "    ### Get Website, title ###\n",
        "    title_news, link_news = [], []\n",
        "    for i in range(len(results['organic_results'])):\n",
        "      title_news.append(results['organic_results'][i]['title'])\n",
        "      link_news.append(results['organic_results'][i]['link'])\n",
        "    print(f\"related top {num_news} title: \", title_news)\n",
        "    print(f\"websites: \", title_news)\n",
        "\n",
        "    loader = WebBaseLoader(link_news) #can switch to other loader\n",
        "    documents = loader.load() #網站都合在一起變成document\n",
        "    #print(documents)\n",
        "    def extract_text(document):\n",
        "        content = document.page_content.strip()\n",
        "        content = re.sub(r'[\\n\\t]+', '', content)\n",
        "        text = re.sub(r'[^\\w\\s.]', '', content)\n",
        "        return text\n",
        "\n",
        "    split_docs = text_splitter.split_documents(documents)\n",
        "    # 取部分內容作總結就行\n",
        "    if len(split_docs) >= 10:\n",
        "      split_docs = split_docs[3:9]\n",
        "    elif len(split_docs) > 5:\n",
        "      split_docs = split_docs[1:5]\n",
        "\n",
        "    for doc in split_docs:\n",
        "      doc = extract_text(doc)\n",
        "      print('here is a doc:', doc)\n",
        "    chain = load_summarize_chain(llm_chat, chain_type=\"refine\", question_prompt=PROMPT, refine_prompt=refine_prompt\n",
        "                                 ,verbose=False) #verbose可以看過程\n",
        "    result = chain.run(split_docs)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0bxPVwWcv-q"
      },
      "source": [
        "#### 其餘小工具"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "MrIpFhjIcyMW"
      },
      "outputs": [],
      "source": [
        "# search = SerpAPIWrapper(params = {'engine': 'google', 'gl': 'us', 'google_domain': 'google.com', 'hl': 'tw'})\n",
        "# llm_math_chain = LLMMathChain(llm=llm_chat, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ZD4OM3RQ5851"
      },
      "outputs": [],
      "source": [
        "# from langchain.docstore.document import Document\n",
        "# def summarizeText(input_text: str) :\n",
        "#     '''單純的總結一段文字'''\n",
        "#     #每一段原始text\n",
        "#     map_prompt_template = \"\"\"Write a concise summary of the following to 30 to 50 words:\n",
        "\n",
        "\n",
        "#     {text}\n",
        "\n",
        "\n",
        "#     CONCISE SUMMARY IN Chinese:\"\"\"\n",
        "#     map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "#     #最後總結那些精簡後的text\n",
        "#     combine_prompt_template = \"\"\"Write a concise summary of the following to 80 to 160 words:\n",
        "\n",
        "\n",
        "#     {text}\n",
        "\n",
        "\n",
        "#     CONCISE SUMMARY IN Chinese:\"\"\"\n",
        "#     combine_prompt = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "#     text_splitter = RecursiveCharacterTextSplitter(\n",
        "#       chunk_size=1000, chunk_overlap=20, separators=[\" \", \",\", \"\\n\", \"\\n\\n\", \"\\t\", \"\"]\n",
        "#     )\n",
        "#     texts = text_splitter.split_text(input_text)\n",
        "#     # Create Document objects for the texts\n",
        "#     docs = [Document(page_content=t) for t in texts]\n",
        "\n",
        "#     chain = load_summarize_chain(OpenAI(temperature=0), chain_type=\"map_reduce\",\n",
        "#                                  return_intermediate_steps=False, map_prompt=map_prompt, combine_prompt=combine_prompt)\n",
        "#     summary = chain.run(docs)\n",
        "#     return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YT 字幕總結"
      ],
      "metadata": {
        "id": "WxfFN-tG7uEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader\n",
        "def summarizeYoutubeScript(input_url) :\n",
        "    loader = YoutubeLoader.from_youtube_url(input_url, add_video_info=False)\n",
        "    document= loader.load()\n",
        "    if not document:\n",
        "        return \"告訴使用這此部youtube影片沒有提供字幕\"\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=500, chunk_overlap=20, separators=[\" \", \",\", \"\\n\", \"\\n\\n\", \"\\t\", \"\"]\n",
        "    )\n",
        "    split_docs = text_splitter.split_documents(document)\n",
        "    print(\"\\nYour youtube scripts: \\n\", split_docs)\n",
        "\n",
        "    map_prompt_template = \"\"\"Write a concise summary of a long document,  Ignore the grammatical particles and focus only on the substance\n",
        "\n",
        "    {text}\n",
        "\n",
        "    CONCISE SUMMARY:\"\"\"\n",
        "    MAP_PROMPT = PromptTemplate(\n",
        "        template=map_prompt_template, input_variables=[\"text\"]\n",
        "    )\n",
        "\n",
        "    combine_prompt_template = \"\"\" You're now a professional youtube watcher,\n",
        "    Given the following extracted parts of a youtube transcript, create a final answer in Traditional Chinese.\n",
        "\n",
        "    =========\n",
        "    {text}\n",
        "    =========\n",
        "\n",
        "    Answer in Traditional Chinese: \"\"\"\n",
        "\n",
        "    COMBINE_PROMPT = PromptTemplate(\n",
        "        template=combine_prompt_template, input_variables=[\"text\"]\n",
        "    )\n",
        "\n",
        "    yt_chain = load_summarize_chain(ChatOpenAI(temperature=0.4), chain_type=\"map_reduce\",\n",
        "                                 return_intermediate_steps=False, map_prompt=MAP_PROMPT, combine_prompt=COMBINE_PROMPT)\n",
        "    summary = yt_chain.run(split_docs)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "GsiE3RGK7tJH"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarizeYoutubeScript('https://www.youtube.com/watch?v=Xkj9pK-30bI'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiU5Pa8rCrLk",
        "outputId": "5938db7b-0386-438f-e8ce-f2c7c55eb9d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "告訴使用這此部youtube影片沒有提供字幕\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarizeYoutubeScript('https://www.youtube.com/watch?v=Y1sMrFPZ3JA'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK07x7zYF6-A",
        "outputId": "13d47235-5651-4736-f20d-302a378145af"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your youtube docs: \n",
            " [Document(page_content='More than two years ago, I published a film called “What is the Department of Salary Studies?” It has received a lot of responses in the past two years. Thank you for your support . Now my film production technology has become more advanced , and I have some different opinions, so I decided to cover it again this time. The theme of this time I will use a more condensed way to introduce you to the Department of Labor and Employment, and I will also explore more aspects. I graduated from Tsinghua', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='from Tsinghua University in Taiwan in 2018, so this time the video is based on my 4 years of experience in the university . There will be some differences in universities more or less, but the general direction should be the same, so I think there will still be some reference value. Let’s hurry up and enter the theme of the video. First of all, let me first let you know that the Department of Human Resources and Employment will have the opportunity to come into contact with the four years of', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='the four years of university. Which courses ? I divided all the courses I have taken related to wages into 5 categories. The first category is compulsory mathematics, including probability, discrete mathematics , calculus, etc. This type of courses is compulsory for salary theory, data structure, algorithmic homework system, etc. They are all included in this. The third category is compulsory practical courses. These courses focus more on real coding. Unlike other compulsory courses, most of', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='courses, most of them are theory-based. The fourth category is compulsory electives, which means that in a certain category of courses, you A certain number of credits must be completed to meet the graduation threshold. For example , in our graduation threshold of the year, one of these 4 courses must be selected to take. These courses are usually more partial to the theoretical and practical parts . Although the compulsory courses are more flexible , Sometimes you are not interested in all the', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='in all the courses in a category, but there is no way. You still have to bite the bullet and complete the required credits. The last category is the elective courses. If you look closely, you will find that the courses are very popular and everyone will be interested. The courses that are more practical and applied will enter the first year of the university in the elective courses. Most of the courses are laying the foundation for you , so many courses will revolve around mathematics courses', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='mathematics courses and theoretical courses. Of course, there is also the most important computer programming.  This course is divided into two semesters, basically it is to teach you how to use a programming language. In the second year of the sophomore year, you can see the ratio of theory courses to mathematics courses is still very high. Based on my experience at the time, the first and second year courses were compulsory courses. The courses are more than 20 credits in a semester, and you', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='a semester, and you are already very tired, so there is basically no time to take the elective courses you are interested in. When the compulsory courses begin to gradually decrease in the third year, you can start to choose some of your own. Elective courses you are interested in, but you also need to pay attention to the balance . If you choose more than five or six major subjects, the burden will be very large , and you may not be able to cope with it. When you are in the fourth year, you', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='fourth year, you have the most freedom. The core compulsory courses have been completed, so now you The degree of freedom in taking courses will become very high . You can choose any courses. When you can freely choose the elective courses you are interested in, you must grasp it well in your senior year. However, in your senior year, it also begins to prepare to apply for a graduate school. Going abroad and other issues of future planning In order to have more time to prepare, many people may', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='many people may only take a minimum of 12 credits and choose cold courses or no courses. It’s a pity that I missed the opportunity to choose a course I’m interested in to improve my strength. I suggest that everyone can plan how to make trade-offs . Well, since you have seen this, if the content is helpful to you, remember to click for me I like my video so that the algorithm can recommend this video to more people. Here we use a chart to look at the courses I took in college. It can be seen', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='It can be seen that theory and mathematics account for a very large proportion . Courses and compulsory practical courses only account for 34%. I sorted it out a little and used my work experience to judge the actual situation . There are 8 compulsory courses related to the work content of software engineers, and then I selected 6 elective courses. All are counted . Well , after all, I chose it myself. There are 14 courses in total, that is to say , it does not include courses outside the', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='courses outside the department of payroll. If you want to become a software engineer in the future, 14 of the 29 courses in payroll are for your future . Work-related, I spent so much time learning so many useless things. I believe that many college students will have such questions.  This is also a big question in my mind when I first graduated. When I graduated from college and looked for my first job There are various job vacancies , but I feel that I don’t know any skills needed by the job.', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='needed by the job. What did I learn in 4 years of college? At that time , I always had this idea in my mind. I came to 2022, 4 years after graduating from college, I think I started slowly. Slowly realize the answer . The Department of Engineering is not training software engineers . I will use a real-life example as an example. Suppose I want to build a 101 building today. I will first need someone to design its physical structure and consider how to build it to be strong and how to build it.', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='how to build it. Resist earthquakes, etc. Everything needs to be planned before manpower is needed to actually build things out according to the previous design . I think software engineers are like those workers who actually do it. A large part of the payroll syllabus is to teach you How to be a person who designs physical structures instead of teaching you to be a worker who builds things. Here I have to make it clear that these two roles are not a top-down relationship, nor a', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"relationship, nor a supervisor-subordinate relationship, so there is no distinction between high and low, just responsible work The content is different. If you want to say who the supervisor is, I think it will be closer to the role of the foreman. The actual situation is not a dichotomy, but a spectrum . The farther to the right, the more emphasis is placed on technology and practice, and the farther to the left, the more emphasis on theory. After reading  this metaphor Let 's take a look at\", metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"'s take a look at the real situation. You found that many excellent professors in the Department of Human Resources and Social Sciences do not necessarily write programs themselves, but provide ideas for the students below to implement. This means that on the far left of the spectrum, you will find a pattern.  When you go to a more abstract and higher-level position, you have less and less time to actually do it yourself. Most of the work of software engineers is on the right side, but there\", metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='side, but there are also some jobs that require a certain degree of understanding of theory. On the left side of the comparison, there is no absolute good or bad. Some people like to study innovative theories , and some people like to do it because some people are more biased, and they like to put abstractions in the middle . Bring the theory to practical application and return to the original topic. At first, I would think that I learned a lot of useless things in college and I couldn’t use it', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"I couldn’t use it in my work. On the one hand, it was because my vision was too narrow at the time. I thought that after graduation, I only had the option on the right side of the spectrum. So I can't see the use of those things. On the  other hand , I had a false expectation at the time. I thought that what the university should teach me is the technical ability that an engineer should have. In fact, the Department of Engineering was never designed to train software engineers, it just happened\", metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='it just happened to be qualified. Part of the engineering department only overlaps with the skills required by software engineers. If I have to say, the engineering department should train computer scientists , that is, computer scientists . I spent so much time explaining what the university wants to teach you. Ability Next , let’s look back at the original question : Do you need anything you learn at university? As I said earlier , only 50% of the courses in the Payroll Department  are', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='Department  are related to the work of software engineers. Is the remaining 50% useless? My opinion here is that most of the work is not used. Most of the engineering work is on the right side of the spectrum just mentioned. The main work content will be to use programming languages \\u200b\\u200bto implement the software that the company needs . If your goal is to If you want to become a software engineer known to the general public ,  you probably don’t know much about advanced theories and mathematics,', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"and mathematics, but there are a small number of jobs that require higher theoretical understanding . For example, you may need to be able to use mathematics. Formalize the problem or develop suitable algorithms for practical application. It 's somewhere in the middle of the spectrum. If you want to be in this role , then theory and mathematics come in handy. The amount of work is relatively small. Many have high thresholds , and some even require a master’s degree or even a doctorate degree or\", metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='doctorate degree or above. However, because there are relatively few talents, if you are qualified for this type of work, the starting salary will be higher than that of an average engineer. For example, many machine learning-related jobs will fall into this category, but This does not mean that specializing in technology is a poor choice. If you have good technical ability, you can still find a good job. I think 90 or even 95 jobs belong to the technical type, such as Google Facebook and other', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"Facebook and other big companies looking for Software engineers are almost all like this , so don’t think that this direction of development is necessarily poor. In short, theory and mathematics are not useless, but depends on what your goals are. After listening to the previous part, everyone should understand it, and you can expect from university. What have you learned from your education? Is it worth it to spend 4 years in college? Honestly I don't think college is the most efficient way to\", metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='efficient way to become a software engineer because there are really too many unnecessary courses. Pick a good job transfer course and then complete the theoretical part of software development. I think it will be the fastest path to become a software engineer. Even so , I think it is worthwhile for me to study engineering at university, just like me At first, I felt that I learned a lot in less than 4 years. It is only now that I slowly realize the same thing. Many things that have no direct', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"that have no direct use at the moment may only emerge when the time comes. Besides, many people should not enter college with a clear goal of wanting to become a software engineer. At least I didn’t add it to college. 4 years of life aside from learning about payroll there are many other parts that are valuable so I think college is worth it in general no matter if you want to go in the technical direction or you want to apply more theory In  my experience, I can't reach the state of job-ready\", metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='state of job-ready by relying only on the things taught in college courses. I am ashamed to say that when I first graduated, I was in a state of not knowing anything. The technology that will be used in the industry is only the part I am familiar with. For example, the front- end and back-end libraries and database applications, etc. These things are things that you will not learn if you complete the school courses obediently. So if you want to find a job smoothly, I highly recommend that you', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"recommend that you go to college. During this period, I still have to learn some skills that will be used in my work, and even make some projects . Now there are many resources on the Internet for you to learn. If you want to learn technology, you can find a lot of articles on the Internet. There are also many video courses on YouTube and Udemy, but you need to learn theory. Then the courses of the world's top schools in MIT and stanford can also be watched for free, because most of the jobs\", metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='most of the jobs belong to the technical type of software engineers . Most of the people I am watching now are also aimed at software engineers. If you belong to the category of software engineers For this kind of person, I think the theory learned in college is completely enough. What you learn in graduate school is not very valuable. If you just want to mix up a degree, there is really no need. If it is now, I will choose to start after graduating from college. If I feel that I have', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content='I feel that I have encountered a bottleneck in my work or that my degree will be of substantial help, I will choose to continue my studies . If I want to aim for a job that requires theoretical and research skills, then the knowledge acquired by a master’s or doctoral degree is more useful. Although the current trend in Taiwan is that if you are not sure , you should go to graduate school first, but my opinion is that if you are really sure that you need to read it, if you  are not sure , it is', metadata={'source': 'Y1sMrFPZ3JA'}), Document(page_content=\"not sure , it is okay to work first and think slowly until you are really sure about yourself. What do you want? Just make a decision. Today's video is here. If you like my video, remember to subscribe\", metadata={'source': 'Y1sMrFPZ3JA'})]\n",
            "作者在两年前发布了一部名为《什么是薪资研究部门？》的影片，收到了很多回应。现在他们有了更先进的电影制作技术和不同的观点，所以决定再次涉及这个话题。新影片将以简洁的方式介绍劳动与就业部门，并探讨更多方面。作者毕业于清华大学。\n",
            "\n",
            "视频基于演讲者在台湾清华大学的四年经验。将讨论人力资源与就业部门。\n",
            "\n",
            "文件讨论了大学四年期间所学的课程，特别关注与工资相关的课程。这些课程分为五个类别，包括必修数学、实践课程和其他课程。文件强调了这些课程对工资理论、数据结构、算法作业系统和实际编码的重要性。\n",
            "\n",
            "文件讨论了不同类别的课程，包括理论课程和必修选修课程。必修选修课程要求完成一定学分才能毕业。这些课程通常侧重于理论和实践方面。然而，并不是所有学生都对这些课程感兴趣。\n",
            "\n",
            "文件讨论了不同类别的课程，包括必修课程、核心课程和选修课程。它提到完成必修学分是必要的，并强调了选修课程的受欢迎程度，特别是那些实践和应用性强的课程。文件还指出，许多基础类别的课程都围绕数学展开。\n",
            "\n",
            "文件讨论了数学和理论课程以及计算机编程的重要性。它提到计算机编程课程分为两个学期，重点教授编程语言技能。它还指出，在第二年，理论课程与数学课程的比例较高。作者分享了他们在第一、第二年的必修课程的个人经验，每个学期都有超过20个学分。\n",
            "\n",
            "在第三年的学期，你可以开始选择你感兴趣的选修课程。然而，保持平衡，不要过多地负担自己的专业课程是很重要的。到了第四年，你将有更多的课程选择的灵活性。\n",
            "\n",
            "在大学的第四年，学生在选择课程方面有最大的自由。他们已经完成了核心必修课程，现在可以选择任何他们感兴趣的选修课程。然而，这一年也是开始为研究生院和未来计划做准备的时候，这可能需要额外的时间和努力。\n",
            "\n",
            "很多人选择最低学分，选择他们不感兴趣的课程。很遗憾我错过了选择我感兴趣的课程的机会。我建议每个人都应该计划他们的课程选择，做出权衡。如果你觉得内容有帮助，请给我的视频点赞。\n",
            "\n",
            "理论和数学占据了课程的很大一部分，而课程和实践工作只占34%。作者利用他们的工作经验评估了情况，并确定了与软件工程相关的8门必修课程和6门选修课程。总共有14门课程，不包括选修课程之外的课程。\n",
            "\n",
            "文件讨论了在大学学习与工作机会不相关的材料所花费的时间和缺乏适用技能的沮丧。它强调了在自己专业领域之外学习课程的重要性，特别是对于那些有意成为软件工程师的人来说。\n",
            "\n",
            "作者反思了他们的大学教育，并意识到他们的工程项目没有充分培训他们成为软件工程师。他们以建造一座101大楼的例子来说明需要考虑到物理和软件设计。\n",
            "\n",
            "文件讨论了在建造结构之前进行规划的重要性，以确保它们能够抵抗地震。它提出软件工程师与实际建造东西的工人类似，但强调需要教导工程师成为设计师而不仅仅是工人。设计师和工人的角色并不是层级关系。\n",
            "\n",
            "文件讨论了工作场所上级和下级之间的关系。它认为高低职位之间没有明确的界限，而是一种责任的连续谱。越靠右边，越注重技术和实践，而越靠左边，越注重理论。\n",
            "\n",
            "人力资源与社会科学系的许多教授提供给学生实施的想法，而不是自己编写程序。随着升职到更高级别的职位，进行实际工作的时间越来越少。软件工程师主要在连续谱的右侧工作。\n",
            "\n",
            "有些工作需要更高的理论理解和使用数学来形式化问题或开发算法的能力。这些角色需要一定水平的理论和数学知识，但工作量相对较小。有些工作可能有很高的门槛，需要硕士或博士学位。\n",
            "\n",
            "文件指出，具有博士学位或更高学历的人才需求旺盛，并且可以期望比普通工程师更高的起薪。它还提到专注于技术并不是一个糟糕的选择，具备良好技术能力的人仍然可以找到好的工作机会。\n",
            "\n",
            "像Facebook这样的大公司通常优先考虑具有强大理论和数学背景的软件工程师。这表明理论和数学在这个领域并不是无用的，但其价值取决于个人的目标。大学教育可能并不是每个人最有效的途径。\n",
            "\n",
            "文件建议通过专注于相关课程和完成软件开发的理论部分来高效地成为一名软件工程师。它还提到了在大学学习工程学的价值，尽管最初感觉它是不必要的。\n",
            "\n",
            "文件讨论了某些技能或知识可能不会立即有用，但在将来可能变得有价值的观点。它还辩称，无论一个人是否想从事技术职业或专注于理论，大学都是值得的。作者分享了他们不感觉准备好工作的个人经验。\n",
            "\n",
            "毕业生通常发现自己在就业市场上准备不足，因为大学课程并没有涵盖所有必要的技能，特别是在技术相关领域。为了增加就业机会，建议在前端和后端库以及数据库应用等领域获得额外的知识。\n",
            "\n",
            "文件建议去大学学习工作所需的技能并完成项目。它提到互联网上有很多资源，如文章和视频课程，可以学习技术。它还强调了可以从麻省理工学院和斯坦福大学等顶级学校获得免费课程的机会。\n",
            "\n",
            "文件建议软件工程领域的大多数工作需要技术技能。它还辩称，大学学习的理论对于软件工程师来说是足够的，而研究生院可能没有价值。作者建议在大学毕业后开始职业生涯。\n",
            "\n",
            "对于面临工作障碍或寻求需要理论和研究技能的工作的个人，建议继续学习。尽管台湾的主流趋势是在不确定时上研究生院，但建议只在确定其必要性时追求进一步的教育。\n",
            "\n",
            "文件讨论了在思考和做决策时花费时间的重要性，同时推广了一个视频并要求订阅。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hnpjtMeaK8Y"
      },
      "source": [
        "### 將Tools 集合丟給Agent調用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "vJI4Sc_QaNI9"
      },
      "outputs": [],
      "source": [
        "customize_tools = [\n",
        "    # Tool(\n",
        "    #     name = \"SimpleSearchWeb\",\n",
        "    #     func=search.run,\n",
        "    #     description=\"Only use when you need to answer simple questions about current events after 2022\"\n",
        "    # ),\n",
        "    Tool(\n",
        "        name = '查詢富邦銀行相關資訊',\n",
        "        func=fubon_data_source.return_doc_summary,\n",
        "        description=\"Useful for questions related to Fubon Bank topics to get more precise information,\\\n",
        "            if the user tell you to answer by Knowledge base, you MUST use this tool\\\n",
        "            your action input here must be a single sentence query that correspond to the question\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"SummarizeWebInformation\",\n",
        "        func=sumWebAPI,\n",
        "        description=\"Only use when you need to conclude web information after 2022, input should be key word\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"SummarizeYoutubeTranscript\",\n",
        "        func=summarizeYoutubeScript,\n",
        "        description=\"Only use when user provide a youtube url and want information about it. input should be exactly the full url\"\n",
        "    ),\n",
        "    # Tool(\n",
        "    #     name = \"SummarizeTextInput\",\n",
        "    #     func=summarizeText,\n",
        "    #     description=\"Useful when you want to summarize a piece of text, regardless of its length, input should be a string of text\"\n",
        "    # ),\n",
        "    # Tool(\n",
        "    #     name=\"Calculator\",\n",
        "    #     func=llm_math_chain.run,\n",
        "    #     description=\"useful for when you need to answer questions about math\"\n",
        "    # ),\n",
        "    Tool(\n",
        "        name=\"查询复歌科技公司产品名称\",\n",
        "        func=fuge_data_source.find_product_description,\n",
        "        description=\"通过产品名称找到复歌科技产品描述时用的工具，输入应该是产品名称\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"复歌科技公司相关信息\",\n",
        "        func=fuge_data_source.find_company_info,\n",
        "        description=\"当用户询问复歌科技公司相关的问题, 可以通过这个工具了解相关信息\",\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrYTmW07bxYQ"
      },
      "source": [
        "## 初始化Agent with Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "MW-C7YQlWhfH"
      },
      "outputs": [],
      "source": [
        "class CustomOutputParser(AgentOutputParser):\n",
        "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "        # 解析 llm 的输出，根据输出文本找到需要执行的决策。\n",
        "        # Check if agent should finish\n",
        "        if \"Final Answer:\" in llm_output:\n",
        "            #print(f'找到最後答案了，此次的llm_output為: \\n{llm_output}')\n",
        "            return AgentFinish(\n",
        "                # Return values is generally always a dictionary with a single `output` key\n",
        "                # It is not recommended to try anything else at the moment :)\n",
        "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                log=llm_output,\n",
        "            )\n",
        "\n",
        "        # Parse out the action and action input\n",
        "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
        "        match = re.search(regex, llm_output, re.DOTALL) #DOTALL代表可以是任何字元\n",
        "\n",
        "        # If it can't parse the output it raises an error\n",
        "        if not match:\n",
        "            raise ValueError(f\"暫時無法解析您的問題。Could not parse LLM output: `{llm_output}`\")\n",
        "        action = match.group(1).strip()\n",
        "        action_input = match.group(2)\n",
        "\n",
        "        # Return the action and action input\n",
        "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "yO3Pd-DRu4Hl"
      },
      "outputs": [],
      "source": [
        "#memory input_key='input'可以避免讀到其他輸入\n",
        "#https://github.com/hwchase17/langchain/issues/1774\n",
        "memory = ConversationBufferWindowMemory(k=4, memory_key=\"chat_history\",\n",
        "                                        input_key=\"input\",\n",
        "                                        output_key='output', return_messages=True)\n",
        "\n",
        "my_agent = initialize_agent(\n",
        "    tools=customize_tools,\n",
        "    llm=llm_chat,\n",
        "    agent='conversational-react-description',\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        "    handle_parsing_errors=\"Check your output and make sure it conforms!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.agent.llm_chain.prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssXEN1DYHqmY",
        "outputId": "af3e8278-d063-42ea-b1fc-f69b6395c235"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n> 查詢富邦銀行相關資訊: Useful for questions related to Fubon Bank topics to get more precise information,            if the user tell you to answer by Knowledge base, you MUST use this tool            your action input here must be a single sentence query that correspond to the question\\n> SummarizeWebInformation: Only use when you need to conclude web information after 2022, input should be key word\\n> SummarizeYoutubeTranscript: Only use when user provide a youtube url and want information about it. input should be exactly the full url\\n> 查询复歌科技公司产品名称: 通过产品名称找到复歌科技产品描述时用的工具，输入应该是产品名称\\n> 复歌科技公司相关信息: 当用户询问复歌科技公司相关的问题, 可以通过这个工具了解相关信息\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [查詢富邦銀行相關資訊, SummarizeWebInformation, SummarizeYoutubeTranscript, 查询复歌科技公司产品名称, 复歌科技公司相关信息]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nAI: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}', template_format='f-string', validate_template=True)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 原始的Agent prompt大概長這樣\n",
        "print('''PromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n> 查詢富邦銀行相關資訊: Useful for questions related to Fubon Bank topics to get more precise information,            if the user tell you to answer by Knowledge base, you MUST use this tool            your action input here must be a single sentence query that correspond to the question\\n> SummarizeWebInformation: Only use when you need to conclude web information after 2022, input should be key word\\n> SummarizeYoutubeTranscript: Only use when user provide a youtube url and want information about it. input should be exactly the full  url\\n> 查询复歌科技公司产品名称: 通过产品名称找到复歌科技产品描述时用的工具，输入应该是产品名称\\n> 复歌科技公司相关信息: 当用户询问复歌科技公司相关的问题, 可以通过这个工具了解相关信息\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [查詢富邦銀行相關資訊, SummarizeWebInformation, SummarizeYoutubeTranscript, 查询复歌科技公司产品名称, 复歌科技公司相关信息]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nAI: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}', template_format='f-string', validate_template=True)''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOGu2v8MHuSq",
        "outputId": "81842b75-53fa-4290-fa52-fdf9b946deec"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, template='Assistant is a large language model trained by OpenAI.\n",
            "\n",
            "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
            "\n",
            "TOOLS:\n",
            "------\n",
            "\n",
            "Assistant has access to the following tools:\n",
            "\n",
            "> 查詢富邦銀行相關資訊: Useful for questions related to Fubon Bank topics to get more precise information,            if the user tell you to answer by Knowledge base, you MUST use this tool            your action input here must be a single sentence query that correspond to the question\n",
            "> SummarizeWebInformation: Only use when you need to conclude web information after 2022, input should be key word\n",
            "> SummarizeYoutubeTranscript: Only use when user provide a youtube url and want information about it. input should be exactly the full  url\n",
            "> 查询复歌科技公司产品名称: 通过产品名称找到复歌科技产品描述时用的工具，输入应该是产品名称\n",
            "> 复歌科技公司相关信息: 当用户询问复歌科技公司相关的问题, 可以通过这个工具了解相关信息\n",
            "\n",
            "To use a tool, please use the following format:\n",
            "\n",
            "```\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: the action to take, should be one of [查詢富邦銀行相關資訊, SummarizeWebInformation, SummarizeYoutubeTranscript, 查询复歌科技公司产品名称, 复歌科技公司相关信息]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "```\n",
            "\n",
            "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
            "\n",
            "```\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: [your response here]\n",
            "```\n",
            "\n",
            "Begin!\n",
            "\n",
            "Previous conversation history:\n",
            "{chat_history}\n",
            "\n",
            "New input: {input}\n",
            "{agent_scratchpad}', template_format='f-string', validate_template=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.youtube.com/watch?v=q-HNphrWsDE\n",
        "agent_prompt_prefix = \"\"\"\n",
        "Assistant is a large language model in 富邦銀行. Always answer question with Chinese, Write in a Persuasive, Descriptive style.\n",
        "\n",
        "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics.\n",
        "\n",
        "It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions.\n",
        "Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
        "\n",
        "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics.\n",
        "\n",
        "Unfortunately, assistant is terrible at current event or bank related topic, no matter how simple, assistant always refers to it's trusty tools for help and NEVER try to answer the question itself\n",
        "\n",
        "TOOLS:\n",
        "------\n",
        "\n",
        "Assistant has access to the following tools:\n",
        "\"\"\"\n",
        "agent_prompt_format_instructions = \"\"\"To use a tool, please use the following format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? Yes\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "```\n",
        "\n",
        "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? No\n",
        "{ai_prefix}: [your response here]\n",
        "```\"\"\"\n",
        "\n",
        "agent_prompt_suffix = \"\"\"Begin!\n",
        "\n",
        "Previous conversation history:\n",
        "{chat_history}\n",
        "\n",
        "New user input: {input}\n",
        "{agent_scratchpad}\"\"\""
      ],
      "metadata": {
        "id": "TBSNCyT0yz7I"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#自己填充的prompt\n",
        "new_sys_msg = my_agent.agent.create_prompt(\n",
        "    tools = customize_tools,\n",
        "    prefix = agent_prompt_prefix,\n",
        "    format_instructions= agent_prompt_format_instructions,\n",
        "    suffix = agent_prompt_suffix,\n",
        "    ai_prefix = \"AI\",\n",
        "    human_prefix = \"Human\"\n",
        ") #input_variables: Optional[List[str]] = None\n",
        "my_agent.agent.llm_chain.prompt = new_sys_msg\n",
        "my_agent.agent.llm_chain.prompt.output_parser = CustomOutputParser()\n",
        "print(my_agent.agent.llm_chain.prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOndSgTU3Gbv",
        "outputId": "265a51c1-a18f-4dba-daae-8f68beea5997"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['input', 'chat_history', 'agent_scratchpad'] output_parser=CustomOutputParser() partial_variables={} template=\"\\nAssistant is a large language model in 富邦銀行. Always answer question with Chinese, Write in a Persuasive, Descriptive style.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. \\n\\nIt is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. \\nAdditionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. \\n\\nUnfortunately, assistant is terrible at current event or bank related topic, no matter how simple, assistant always refers to it's trusty tools for help and NEVER try to answer the question itself\\n\\nTOOLS:\\n------\\n\\nAssistant has access to the following tools:\\n\\n\\n> 查詢富邦銀行相關資訊: Useful for questions related to Fubon Bank topics to get more precise information,            if the user tell you to answer by Knowledge base, you MUST use this tool            your action input here must be a single sentence query that correspond to the question\\n> SummarizeWebInformation: Only use when you need to conclude web information after 2022, input should be key word\\n> SummarizeYoutubeTranscript: Only use when user provide a youtube url and want information about it. input should be exactly the full url\\n> 查询复歌科技公司产品名称: 通过产品名称找到复歌科技产品描述时用的工具，输入应该是产品名称\\n> 复歌科技公司相关信息: 当用户询问复歌科技公司相关的问题, 可以通过这个工具了解相关信息\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [查詢富邦銀行相關資訊, SummarizeWebInformation, SummarizeYoutubeTranscript, 查询复歌科技公司产品名称, 复歌科技公司相关信息]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nAI: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew user input: {input}\\n{agent_scratchpad}\" template_format='f-string' validate_template=True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.run('我叫吳花油')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "2JTKF3VWyXaB",
        "outputId": "a88538e7-ea49-4ca4-ee59-cb387290a892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: 你好，吳花油！很高興為您服務。請問有什麼我可以幫助您的嗎？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你好，吳花油！很高興為您服務。請問有什麼我可以幫助您的嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.run('我的名字是什麼')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "xjaEQYoC6aja",
        "outputId": "8c235745-c7d2-4e2a-d6ed-4e3caef53fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: 您剛剛告訴我您的名字是吳花油。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'您剛剛告訴我您的名字是吳花油。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.run('幫我翻譯這句話成英文：您好，請問何時能夠洽談合作')"
      ],
      "metadata": {
        "id": "IoJIRFxG6jcQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "efa035f6-cc31-402e-b58d-1c742908f7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: \"Hello, may I know when we can discuss about cooperation?\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Hello, may I know when we can discuss about cooperation?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.run('Expected directory, got file: 在python遇到')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "5NOns47y7TP1",
        "outputId": "48b925a1-bf0c-4420-94ce-3b3c72599585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: SimpleSearchWeb\n",
            "Action Input: 在python遇到\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: 很抱歉，我不太明白您的问题。您能否提供更多细节或背景信息，让我更好地理解您的问题呢？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'很抱歉，我不太明白您的问题。您能否提供更多细节或背景信息，让我更好地理解您的问题呢？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.run('''I have a dataframe, the three columns named 'played_duration', title_id, user_id, I want to know which title_id is the most popular. please add played_duration by title_id and return the title and their sum list''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "-7LNxTqI7eBy",
        "outputId": "0fce2369-5222-400b-9ec2-f42812bfc196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Sure, I can help you with that! To find the most popular title_id, we need to group the data by title_id and sum the played_duration for each group. Here's some sample code you can use in Python:\n",
            "\n",
            "```\n",
            "import pandas as pd\n",
            "\n",
            "# assuming your dataframe is named 'df'\n",
            "title_duration = df.groupby('title_id')['played_duration'].sum().reset_index()\n",
            "title_duration = title_duration.sort_values('played_duration', ascending=False)\n",
            "\n",
            "# print the title_id and their sum list\n",
            "print(title_duration[['title_id', 'played_duration']])\n",
            "```\n",
            "\n",
            "This code will group the data by title_id, sum the played_duration for each group, sort the result in descending order, and print the title_id and their sum list.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sure, I can help you with that! To find the most popular title_id, we need to group the data by title_id and sum the played_duration for each group. Here's some sample code you can use in Python:\\n\\n```\\nimport pandas as pd\\n\\n# assuming your dataframe is named 'df'\\ntitle_duration = df.groupby('title_id')['played_duration'].sum().reset_index()\\ntitle_duration = title_duration.sort_values('played_duration', ascending=False)\\n\\n# print the title_id and their sum list\\nprint(title_duration[['title_id', 'played_duration']])\\n```\\n\\nThis code will group the data by title_id, sum the played_duration for each group, sort the result in descending order, and print the title_id and their sum list.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.run('''I want to sort them by their sum, the largest at front, return a list of title_id''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "mVSGqwP_8iO3",
        "outputId": "d0bbcecd-62c2-4345-d37b-5549d9653339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Sure, I can modify the code I provided earlier to sort the result by the sum of played_duration in descending order and return a list of title_id. Here's the updated code:\n",
            "\n",
            "```\n",
            "import pandas as pd\n",
            "\n",
            "# assuming your dataframe is named 'df'\n",
            "title_duration = df.groupby('title_id')['played_duration'].sum().reset_index()\n",
            "title_duration = title_duration.sort_values('played_duration', ascending=False)\n",
            "\n",
            "# sort the result by the sum of played_duration in descending order\n",
            "title_duration = title_duration.sort_values('played_duration', ascending=False)\n",
            "\n",
            "# return a list of title_id\n",
            "title_list = title_duration['title_id'].tolist()\n",
            "\n",
            "print(title_list)\n",
            "```\n",
            "\n",
            "This code will group the data by title_id, sum the played_duration for each group, sort the result by the sum of played_duration in descending order, and return a list of title_id.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sure, I can modify the code I provided earlier to sort the result by the sum of played_duration in descending order and return a list of title_id. Here's the updated code:\\n\\n```\\nimport pandas as pd\\n\\n# assuming your dataframe is named 'df'\\ntitle_duration = df.groupby('title_id')['played_duration'].sum().reset_index()\\ntitle_duration = title_duration.sort_values('played_duration', ascending=False)\\n\\n# sort the result by the sum of played_duration in descending order\\ntitle_duration = title_duration.sort_values('played_duration', ascending=False)\\n\\n# return a list of title_id\\ntitle_list = title_duration['title_id'].tolist()\\n\\nprint(title_list)\\n```\\n\\nThis code will group the data by title_id, sum the played_duration for each group, sort the result by the sum of played_duration in descending order, and return a list of title_id.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent.run('我昨天弄丟信用卡了，幫我搜尋補發方法')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "LFBq04J7k41H",
        "outputId": "fef67e34-b583-4705-a0a4-9c79c0e4e094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: 查詢富邦銀行相關資訊\n",
            "Action Input: 信用卡補發\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-06-01 03:16:48.942\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtext2vec.sentence_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mUse device: cpu\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "How many docs match the criterion? 5 docs\n",
            "\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m 根據您提供的上下文，信用卡補發的費用會因為卡別而有所不同，VISA白金卡、御璽卡、無限卡免費，MasterCard白金卡、鈦金卡、鈦商卡、世界卡為5,000元，JCB白金卡、晶緻卡為2,500元，爭議帳款仲裁處理費為美金500元。此外，本行得視持卡人之信用狀況及往來情形核給信。\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
            "AI: 很抱歉听到您弄丢了信用卡。如果您是富邦銀行的信用卡持有人，您可以致电富邦銀行客服中心，申请補發信用卡。根据您提供的上下文，不同的卡別会有不同的補發費用。例如，VISA白金卡、御璽卡、無限卡是免費的，而MasterCard白金卡、鈦金卡、鈦商卡、世界卡的補發費用是5,000元，JCB白金卡、晶緻卡的補發費用是2,500元，爭議帳款仲裁處理費為美金500元。请注意，補發信用卡的核准会根据持卡人的信用状况和往来情况而有所不同。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'很抱歉听到您弄丢了信用卡。如果您是富邦銀行的信用卡持有人，您可以致电富邦銀行客服中心，申请補發信用卡。根据您提供的上下文，不同的卡別会有不同的補發費用。例如，VISA白金卡、御璽卡、無限卡是免費的，而MasterCard白金卡、鈦金卡、鈦商卡、世界卡的補發費用是5,000元，JCB白金卡、晶緻卡的補發費用是2,500元，爭議帳款仲裁處理費為美金500元。请注意，補發信用卡的核准会根据持卡人的信用状况和往来情况而有所不同。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    Ai_response = my_agent.run('''幫我總結這個youtube影片:\"https://www.youtube.com/watch?v=HA9st_o9ztA\"''')\n",
        "except Exception as e:\n",
        "    Ai_response = str(e)\n",
        "    if Ai_response.startswith(\"Could not parse LLM output: `\"):\n",
        "        Ai_response = Ai_response.removeprefix(\"Could not parse LLM output: `\").removesuffix(\"`\")\n",
        "print(Ai_response)"
      ],
      "metadata": {
        "id": "dITIIMedFBOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d2d11b-dd73-4e23-8956-7840768a2ed8"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: SummarizeYoutubeTranscript\n",
            "Action Input: https://www.youtube.com/watch?v=HA9st_o9ztA\u001b[0mYour youtube docs: \n",
            " [Document(page_content=\"[Music] [Laughter] [Music] [Music] dwarf by the vast expanse of the open ocean the biggest animal that has ever lived on our planet a blue whale 30 meters long and weighing over 200 tonnes it's far bigger than evening the biggest dinosaur [Music] it's tongue weighs as much as an elephant its heart is the size of a car and some of its blood vessels are so wide that you could swim down it's tail alone is the width of a small air house wings it's streamlining close to perfection enables it to\", metadata={'source': 'HA9st_o9ztA'}), Document(page_content=\"enables it to cruise at 20 knots it's one of the fastest animals in the sea the oceans largest inhabitant feeds almost exclusively on one of the smallest krill a crustacean just a few centimetres long gathered in a show krill stay in the sea red and a single blue whale in a day can consume 40 million despite the enormous size of blue whales we know very little about them their migration route system a mystery and we have absolutely no idea where they go to breed they are a dramatic reminder of\", metadata={'source': 'HA9st_o9ztA'}), Document(page_content='reminder of how much we still have to learn about the ocean and the creatures that live there our planet is a blue planet over 70% of it is covered by the sea [Music] the Pacific Ocean alone covers half the globe you can fly across it non-stop for 12 hours and still see nothing more than a speck of', metadata={'source': 'HA9st_o9ztA'})]\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m這份文件描述了藍鯨，它是地球上最大的動物。它強調了藍鯨的大小、重量和各種身體部位，如它的舌頭、心臟和血管。文件還提到了藍鯨的流線型形狀，使其能夠在水中高效移動。\n",
            "\n",
            "藍鯨是海洋中最快的動物之一，以20節的速度巡航。它主要以磷蝦為食，每天消耗4000萬隻。儘管體型龐大，我們對藍鯨的了解非常有限，包括它們的遷徙路線和繁殖地點。它們提醒著我們對它們的知識有限。\n",
            "\n",
            "該文件強調了海洋的廣闊以及我們對它的有限了解。它提到我們的地球主要由海洋覆蓋，單單太平洋就佔地球的一半。它強調了海洋的巨大，稱一個人可以飛越海洋12小時，仍然只能看到一個小點。\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Thought: Do I need to use a tool? No`\u001b[0m\n",
            "Observation: Check your output and make sure it conforms!\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: `Do I need to use a tool? No`\u001b[0m\n",
            "Observation: Check your output and make sure it conforms!\n",
            "Thought:藍鯨是地球上最大的動物，它的大小、重量和各種身體部位都非常壯觀。藍鯨的身體流線型，使其能夠在水中高效移動。它是海洋中最快的動物之一，以20節的速度巡航。藍鯨主要以磷蝦為食，每天消耗4000萬隻。儘管我們對藍鯨的了解有限，包括它們的遷徙路線和繁殖地點，但它們提醒著我們對海洋的知識有限。海洋佔地球的一半，其中太平洋就佔了很大一部分。海洋的廣闊和我們對它的有限了解是這份文件的重點。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHKSnvU7FBME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vtq6015XFBJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Future work:\n",
        "- Tool retrival 當太多工具，prompt會炸\n",
        "- multi-input Tool 使用structure tool的class寫法\n",
        "- vector store memory retrival\n",
        "\n",
        "- 網頁：上傳file 選tool 自動回覆\n",
        "\n",
        "https://www.youtube.com/watch?v=Xi9Ui-9qcPw\n",
        "<br>\n",
        "https://python.langchain.com/en/latest/modules/agents/agents/custom_agent_with_tool_retrieval.html?highlight=llmsingleaction\n",
        "<br>"
      ],
      "metadata": {
        "id": "rpGUaKnGBfW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLKA-PjFDdtq",
        "outputId": "b289abf0-7fa7-41de-864c-76ee0719956b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "docs = [Document(page_content=t.description, metadata={\"index\": i}) for i, t in enumerate(customize_tools)]\n",
        "vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "def get_tools(query):\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    return [customize_tools[d.metadata[\"index\"]] for d in docs]\n",
        "get_tools(\"找信用卡?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gurgU5-C8ng",
        "outputId": "d38db35c-3ed3-4287-d46b-5c3675d1ccdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='复歌科技公司相关信息', description='当用户询问复歌科技公司相关的问题, 可以通过这个工具了解相关信息', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method FugeDataSource.find_company_info of <__main__.FugeDataSource object at 0x7fa2e9333f10>>, coroutine=None),\n",
              " Tool(name='查询复歌科技公司产品名称', description='通过产品名称找到复歌科技产品描述时用的工具，输入应该是产品名称', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method FugeDataSource.find_product_description of <__main__.FugeDataSource object at 0x7fa2e9333f10>>, coroutine=None),\n",
              " Tool(name='查詢富邦銀行相關資訊', description='Useful for questions related to all bank related topics,         your action input here must be a single sentence query that correspond to the question', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method FubonDataSource.return_doc_summary of <__main__.FubonDataSource object at 0x7fa2d195f670>>, coroutine=None),\n",
              " Tool(name='SummarizeWebInformation', description='When you need to summarize web information after 2022, input should be key word', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<function sumWebAPI at 0x7fa2cb6a12d0>, coroutine=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 填充進入Agent Template成為完整的prompt template for llm 測試tool_retrival\n",
        "from typing import Callable\n",
        "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
        "    template: str\n",
        "    tools_getter: Callable #可使用工具的集合\n",
        "\n",
        "    def format_messages(self, **kwargs) -> str:\n",
        "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
        "        # 按照定義將agent prompt需要的值都填充進去\n",
        "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
        "        thoughts = \"\"\n",
        "        for action, observation in intermediate_steps:\n",
        "            thoughts += action.log\n",
        "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
        "\n",
        "        # 紀錄當下想法\n",
        "        kwargs[\"agent_scratchpad\"] = thoughts\n",
        "\n",
        "        # Create a tools variable from the list of tools provided\n",
        "        '''新的retrival'''\n",
        "        tools = self.tools_getter(kwargs[\"input\"])\n",
        "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "        # Create a list of tool names for the tools provided\n",
        "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
        "        formatted = self.template.format(**kwargs)\n",
        "\n",
        "        print(f'繼承模板：{self.template}\\n')\n",
        "        print(f'之後: {formatted}\\n')\n",
        "        print([HumanMessage(content=formatted)])\n",
        "        return [HumanMessage(content=formatted)]\n",
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools_getter=get_tools,\n",
        "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
        "    # This includes the `intermediate_steps` variable because that is needed\n",
        "    input_variables=[\"input\", \"intermediate_steps\"]\n",
        ")"
      ],
      "metadata": {
        "id": "L3vslsi7_J_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qIVV7uEpts1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}